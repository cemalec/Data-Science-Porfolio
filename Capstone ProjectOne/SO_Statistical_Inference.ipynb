{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import student data from wrangling stage\n",
    "filepath = '/Users/chrismalec/DS_Portfolio/CapstoneProjectOne/'\n",
    "df_BY = pd.read_pickle(filepath + 'df_BY.pkl')\n",
    "df_weights = pd.read_pickle(filepath + 'df_weights.pkl')\n",
    "labels = pd.read_pickle(filepath + 'labels.pkl')\n",
    "\n",
    "import pickle\n",
    "pickle_in = open(filepath+'number_labels.pkl',\"rb\")\n",
    "number_labels = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests\n",
    "\n",
    "Since the target variable, student outcome as demonstrated by their 2013 transcript, is a categorical variable, I have two types of tests to perform. The first type is the correlation between two discrete variables and the other is correlation between a discrete and continuous variable. In both cases, I will attempt to use a t-test when possible.\n",
    "\n",
    "Another possibilities for discrete variables is to use a chi-squared statistic. A second possibility for discrete vs continuous variables is a biseral pearson coefficient or a fit to the logit function (logistic regression).\n",
    "\n",
    "### Discrete variables\n",
    "\n",
    "The strategy for discrete variables will be to create counts in multiple categories, e.g. students who both dropped out and go to a school with a dropout prevention program and students who dropped out and do not go to a school with a dropout prevention program. If the counts are different, a percent difference in count, and p-value can be calculated. For variables with many categories, a chi-squared test may be more appropriate, as there is no correction needed for multiple hypothesis testing.\n",
    "\n",
    "### Continuous variables\n",
    "\n",
    "For continuous variables the means of the two groups (dropped out - did not drop out) can be compared using a t-test. Since the dropped out group is much smaller, it is important to use unequal variances.\n",
    "\n",
    "### Multiple testing\n",
    "\n",
    "In this dataset, there are hundreds of variables for each student, and therefore some type of correction needs to be made to account for the multiple tests. If no correction is made, and a p-value of 0.05 or less is used to reject the null hypothesis, out of 1000 variables, on average 50 would show statistical significance by pure chance. The Bonferroni correction is the simplist, and involves dividing the p-value by the number of tests, so that statistical significance has a higher bar. This can be overly conservative and miss many real correlations, so I will also try the Holm-Bonferroni correction which sorts the hypothesis tests by p-value from lowest to highest and dividing the critical value by $1/(N - i + 1)$ where $N$ is the number of tests and $i$ is the $i^{th}$ test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'desc': 'X3 Transcript indicated outcome', '1': '\"Fall 2012-summer 2013 graduate\"', '2': '\"Post-summer 2013 graduate\"', '3': '\"Pre-fall 2012 graduate\"', '4': '\"Graduation date unknown\"', '6': '\"Certificate of attendance\"', '8': '\"Dropped out\"', '9': '\"Transferred\"', '10': '\"Left other reason\"', '11': '\"Still enrolled\"', '12': '\"Status cannot be determined\"', '-8': '\"Unit non-response\"'}\n",
      "The total number of students who dropped out in the study was 101 . Corresponding to a total of 17294.0 nationwide\n"
     ]
    }
   ],
   "source": [
    "#Create a mask using the label vector of student outcomes\n",
    "\n",
    "print(number_labels['X3TOUTCOME']) #Is there a way to print out dicts nice?\n",
    "mask = (labels == 8)\n",
    "N_DO = df_weights.loc[mask,'W3STUDENT'].sum()\n",
    "df_weights_DO = df_weights.loc[mask,:]\n",
    "df_weights_nDO = df_weights.loc[~mask,:]\n",
    "print('The total number of students who dropped out in the study was',\n",
    "      np.sum(mask),\n",
    "      '. Corresponding to a total of',\n",
    "      round(N_DO,0),\n",
    "      'nationwide')\n",
    "df_DO = df_BY.loc[mask,:]\n",
    "df_nDO = df_BY.loc[~mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_count(column,df_data,weight,df_weight,code_dict):\n",
    "    replicate_weight_list = [weight +'{:03d}'.format(x) for x in range(1,201)]\n",
    "    df_agg = pd.concat([df_data[column].astype('int64',errors = 'ignore'),df_weight[[weight]+replicate_weight_list]],axis=1)\n",
    "    df_agg = df_agg.groupby(column).sum()\n",
    "    mask = df_agg.index > 0\n",
    "    df_agg =  df_agg.loc[mask,:]#dropping the non-response values, may decide differently later\n",
    "    df_estimate_variance = pd.DataFrame(data={'category':[],'estimate':[],'s.e.':[]})\n",
    "    #For some reason, some numeric variable labels are floats instead of integers, may fix this is cleaning stage.\n",
    "    for i, row in df_agg.iterrows():\n",
    "        #double check std estimation here\n",
    "        N_samp = len(replicate_weight_list)\n",
    "        N_pop = df_agg[weight].sum()\n",
    "        estimate = df_agg.loc[i,weight]/N_pop\n",
    "        variance = ((df_agg.loc[i,replicate_weight_list]/N_pop - estimate)**2).sum()/(N_samp-1)\n",
    "        df_estimate_variance.loc[i] = [code_dict[str(round(i))],\n",
    "                                       estimate,\n",
    "                                       np.sqrt(variance/N_samp)]\n",
    "    \n",
    "    return df_estimate_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'desc': \"X1 Student's sex\", '1': '\"Male\"', '2': '\"Female\"', '-9': '\"Missing\"'}\n",
      "Drop out:\n",
      "    category  estimate      s.e.\n",
      "1    \"Male\"  0.673684  0.012252\n",
      "2  \"Female\"  0.326316  0.005288 \n",
      "\n",
      "Non-drop out:\n",
      "    category  estimate      s.e.\n",
      "1    \"Male\"  0.502636  0.000485\n",
      "2  \"Female\"  0.497364  0.000515 \n",
      "\n",
      "Stat summary:\n",
      "    difference  t_statistic       p-value\n",
      "1    0.171048    13.949089  0.000000e+00\n",
      "2   -0.171048   -13.949089  1.689540e-25 \n",
      "\n",
      "Significance is indicated by p<0.025\n"
     ]
    }
   ],
   "source": [
    "#An example of discrete-discrete hypothesis test one t-test\n",
    "#Null hypothesis is that the count in both categories is the same\n",
    "\n",
    "print(number_labels['X1SEX']) #Description of column\n",
    "N_tests = 2 #get this off of number of rows in aggregated data frame\n",
    "column = 'X1SEX'\n",
    "weight = 'W1STUDENT'\n",
    "\n",
    "df_est_std_DO = estimate_count(column,\n",
    "                               df_DO,\n",
    "                               weight,\n",
    "                               df_weights_DO,\n",
    "                               number_labels[column])\n",
    "\n",
    "df_est_std_nDO = estimate_count(column,\n",
    "                               df_nDO,\n",
    "                               weight,\n",
    "                               df_weights_nDO,\n",
    "                               number_labels[column])\n",
    "\n",
    "df_stats = pd.DataFrame(data={'difference':[],'t_statistic':[],'p-value':[]})\n",
    "for i in df_est_std_DO.index:\n",
    "    se = np.sqrt(df_est_std_DO.loc[1,'s.e.']**2 + df_est_std_nDO.loc[2,'s.e.']**2)\n",
    "    diff = df_est_std_DO.loc[i,'estimate'] - df_est_std_nDO.loc[i,'estimate']\n",
    "    t_statistic = diff/se\n",
    "    df = 100 #Not sure what to put for df here, weighted or unweighted? Maybe just use normal\n",
    "    if diff > 0:\n",
    "        p_value = 1 - stats.t.cdf(t_statistic,df=df)\n",
    "    else:\n",
    "        p_value = stats.t.cdf(t_statistic,df=df)\n",
    "    df_stats.loc[i] = [diff,t_statistic,p_value]\n",
    "    \n",
    "print('Drop out:'+'\\n',df_est_std_DO,'\\n')\n",
    "print('Non-drop out:'+'\\n',df_est_std_nDO,'\\n')\n",
    "print('Stat summary:'+'\\n',df_stats,'\\n')\n",
    "print('Significance is indicated by p<'+str(0.05/N_tests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, males are shown to be a much larger group than females within the dropout category. Males are 17 percentage points higher in the dropout category while females are 17 percentage points lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'desc': 'S1 E01A 9th grader feels safe at school', '1': '\"Strongly agree\"', '2': '\"Agree\"', '3': '\"Disagree\"', '4': '\"Strongly disagree\"', '-8': '\"Unit non-response\"', '-9': '\"Missing\"'}\n",
      "Drop out:\n",
      "               category  estimate      s.e.\n",
      "1     \"Strongly agree\"  0.163576  0.003473\n",
      "2              \"Agree\"  0.600024  0.011062\n",
      "3           \"Disagree\"  0.221125  0.006343\n",
      "4  \"Strongly disagree\"  0.015275  0.001104 \n",
      "\n",
      "Non-drop out:\n",
      "               category  estimate      s.e.\n",
      "1     \"Strongly agree\"  0.304911  0.000508\n",
      "2              \"Agree\"  0.595092  0.000496\n",
      "3           \"Disagree\"  0.077045  0.000265\n",
      "4  \"Strongly disagree\"  0.022952  0.000141 \n",
      "\n",
      "Stat summary:\n",
      "    difference  t_statistic       p-value\n",
      "1   -0.141335   -40.269371  6.541278e-64\n",
      "2    0.004932     0.445407  3.284943e-01\n",
      "3    0.144080    22.696372  0.000000e+00\n",
      "4   -0.007677    -6.894834  2.465504e-10 \n",
      "\n",
      "Significance is indicated by p<0.0125\n"
     ]
    }
   ],
   "source": [
    "#An example of discrete-discrete hypothesis test using multiple t-tests\n",
    "#Null hypothesis is that the count in all non-target categories is the same\n",
    "\n",
    "print(number_labels['S1SAFE']) #Description of column\n",
    "N_tests = 4 #get this off of number of rows in aggregated data frame\n",
    "column = 'S1SAFE'\n",
    "weight = 'W1STUDENT'\n",
    "\n",
    "df_est_std_DO = estimate_count(column,\n",
    "                               df_DO,\n",
    "                               weight,\n",
    "                               df_weights_DO,\n",
    "                               number_labels[column])\n",
    "\n",
    "df_est_std_nDO = estimate_count(column,\n",
    "                               df_nDO,\n",
    "                               weight,\n",
    "                               df_weights_nDO,\n",
    "                               number_labels[column])\n",
    "\n",
    "df_stats = pd.DataFrame(data={'difference':[],'t_statistic':[],'p-value':[]})\n",
    "\n",
    "for i in df_est_std_DO.index:\n",
    "    se = np.sqrt(df_est_std_DO.loc[i,'s.e.']**2 + df_est_std_nDO.loc[i,'s.e.']**2)\n",
    "    diff = df_est_std_DO.loc[i,'estimate'] - df_est_std_nDO.loc[i,'estimate']\n",
    "    t_statistic = diff/se\n",
    "    df = 100 #Not sure what to put for df here, weighted or unweighted? Maybe just use normal\n",
    "    if diff > 0:\n",
    "        p_value = 1 - stats.t.cdf(t_statistic,df=df)\n",
    "    else:\n",
    "        p_value = stats.t.cdf(t_statistic,df=df)\n",
    "    df_stats.loc[i] = [diff,t_statistic,p_value]\n",
    "    \n",
    "print('Drop out:'+'\\n',df_est_std_DO,'\\n')\n",
    "print('Non-drop out:'+'\\n',df_est_std_nDO,'\\n')\n",
    "print('Stat summary:'+'\\n',df_stats,'\\n')\n",
    "print('Significance is indicated by p<'+str(0.05/N_tests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this one test, all but one category had a difference between the proportion of students answering this question a certain way depending on if they were in the 'drop out' or 'non-drop out' category. The strongest effects were that those who 'strongly agreed' that they feel safe at the school were 14% percentage points less likely to be in the drop out category, and those who 'disagreed' that they feel safe at school were 14% percentage points more likely to be in the drop out category. The remaining categories were less than a 1 percentage point difference. (Maybe need to state this differently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_statistic(column,df_data,weight,df_weight,func = np.sum,normalize = True):\n",
    "    replicate_weight_list = [weight +'{:03d}'.format(x) for x in range(1,201)]\n",
    "    analytic_weight = df_weight[weight]\n",
    "    replicate_weights = df_weight[replicate_weight_list]\n",
    "    sum_analytic_weight = analytic_weight.sum()\n",
    "    value = df_data[column]\n",
    "    if(normalize == False):\n",
    "        sum_analytic_weight = 1\n",
    "        \n",
    "    estimate = func(value.multiply(analytic_weight))/sum_analytic_weight\n",
    "    N_samp = len(replicate_weight_list)\n",
    "    replicate_estimates = np.empty(len(replicate_weight_list))\n",
    "    for i,w in enumerate(replicate_weights.columns):\n",
    "        replicate_estimate = func(df_data[column].multiply(replicate_weights[w]))/sum_analytic_weight\n",
    "        replicate_estimates[i] = replicate_estimate\n",
    "    \n",
    "    variance = ((replicate_estimates - estimate)**2).sum()/(N_samp-1)\n",
    "    se = np.sqrt(variance/N_samp)\n",
    "    return (estimate, se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'desc': 'X1 Mathematics standardized theta score'}\n",
      "Drop out: 43.04742118032044 0.7304670767613165 \n",
      "\n",
      "Non-drop out: 50.26713040274542 0.0173492630398546 \n",
      "\n",
      "Stat summary:\n",
      "    difference  t_statistic       p-value\n",
      "1   -7.219709    -9.880902  9.032530e-17 \n",
      "\n",
      "Significance is indicated by p<0.05\n"
     ]
    }
   ],
   "source": [
    "#An example of discrete-continuous hypothesis test\n",
    "#Null hypothesis is that the mean in the target categories is the same\n",
    "print(number_labels['X1TXMTSCOR'])\n",
    "column = 'X1TXMTSCOR'\n",
    "weight = 'W1MATHTCH'\n",
    "N_tests = 1\n",
    "na_mask = df_DO[column] > 0\n",
    "mean_DO, se_DO = estimate_statistic(column,\n",
    "                                    df_DO.loc[na_mask,:],\n",
    "                                    weight,\n",
    "                                    df_weights_DO)\n",
    "\n",
    "mean_nDO, se_nDO = estimate_statistic(column,\n",
    "                                    df_nDO,\n",
    "                                    weight,\n",
    "                                    df_weights_nDO)\n",
    "\n",
    "df_stats = pd.DataFrame(data={'difference':[],'t_statistic':[],'p-value':[]})\n",
    "se = np.sqrt(se_DO**2 + se_nDO**2)\n",
    "diff = mean_DO - mean_nDO\n",
    "t_statistic = diff/se\n",
    "df = 100 #Not sure what to put for df here, weighted or unweighted? Maybe just use normal\n",
    "if diff > 0:\n",
    "    p_value = 1 - stats.t.cdf(t_statistic,df=df)\n",
    "else:\n",
    "    p_value = stats.t.cdf(t_statistic,df=df)\n",
    "df_stats.loc[1] = [diff,t_statistic,p_value]\n",
    "\n",
    "print('Drop out:',mean_DO, se_DO ,'\\n')\n",
    "print('Non-drop out:',mean_nDO, se_nDO,'\\n')\n",
    "print('Stat summary:'+'\\n',df_stats,'\\n')\n",
    "print('Significance is indicated by p<'+str(0.05/N_tests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a statistically significant higher math theta score for non-dropouts. The effect is non-trivial since the range of scores lies between 20 and 80."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automation\n",
    "\n",
    "To automate the process of hypothesis testing, first the type of data must be detected, fortunately, the codebook gives us a convenient label. If the column is a discrete data type, the codebook lists the meaning of each numeric value. The way I have set up the dictionary means that if there is no keys after 'desc', then it is a continuous variable.\n",
    "\n",
    "A stat summary table could be created, and then statistically significant values that pass the more stringent $\\alpha$ value set by the multiple hypothesis testing corrections could be inspected further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
